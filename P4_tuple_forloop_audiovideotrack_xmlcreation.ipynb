{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419a0c98",
   "metadata": {},
   "source": [
    "# Part 4: XML creation\n",
    "## Dependencies: OTIO and pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a85b95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68910a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import pyloudnorm as pyln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecbceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n",
      "Failed to establish dbus connection"
     ]
    }
   ],
   "source": [
    "#video\n",
    "import moviepy\n",
    "from moviepy.editor import *\n",
    "import opentimelineio as otio\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a7e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9bf31",
   "metadata": {},
   "source": [
    "### Quick summary, OTIO can output XML that CAN be used to import timelines. We just need to learn the behavior and then create a loop to automate clipping, using a imported dataframe as a outline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb2dd9",
   "metadata": {},
   "source": [
    "# Timeline Outline behavior testing\n",
    "- First create a list of videos\n",
    "    - sfs\n",
    "- Sec create list of audio\n",
    "\n",
    "- Link audio to video, IE if mic1 use center camera\n",
    "\n",
    "## Use the lists of camera and audio to createa loops creating timeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "852b3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILEPATH_LIST= [\"Batman Middle.mp4\",\"Batman Right.mp4\",\"Batman Left.mp4\"]\n",
    "\n",
    "# \"Batman Right.mp4\" is 1   ||  \"Batman Left.mp4\" is 2\n",
    "AUDIO_FILEPATH_LIST=[\"Data/Audio/Osi Audio Extracted.wav\", \"Data/Audio/Scott Audio Extracted.wav\", \\\n",
    "               \"Data/Audio/Chukwu Audio Extracted.wav\", \"Data/Audio/Crystal Audio Extracted.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672b069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_VIDEO_TUPLE_LIST=[(\"Osi Audio Extracted.wav\", 1), (\"Scott Audio Extracted.wav\",1), \\\n",
    "               (\"Chukwu Audio Extracted.wav\",2), (\"Crystal Audio Extracted.wav\",2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f48b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build the structure\n",
    "tl = otio.schema.Timeline(name=\"Example timeline\")\n",
    "\n",
    "# add track for each video file and each audio file\n",
    "#for each file add a track\n",
    "for i in VIDEO_FILEPATH_LIST :\n",
    "    tr = otio.schema.Track(name=i)\n",
    "    tl.tracks.append(tr)\n",
    "\n",
    "for i in AUDIO_VIDEO_TUPLE_LIST:\n",
    "    tr = otio.schema.Track(name=i[0])\n",
    "    tl.tracks.append(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7847f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing if the tracks are added\n",
    "#otio.adapters.write_to_file(tl, 'Baretimeline.otio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fb9c7",
   "metadata": {},
   "source": [
    "# With the timeline and tracks set, now is the time to match add clips to each of them, Fairly skeleton based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15afba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data with the following: \n",
    "#audio idxmax (we will use this to link the audio video tuple list), \n",
    "#the  list of tuples/intervals \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efb571",
   "metadata": {},
   "source": [
    "# Further data editing \n",
    "\n",
    "## Create a camera view column that matches the audio_video_tuple to  idxmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07ad689",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_pickle('idxmax.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0762e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column linking idxmax to Video File list view\n",
    "data_df['cam_view']= data_df['idxmax'].apply(lambda row: AUDIO_VIDEO_TUPLE_LIST[row-1][1] if row!=0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ba6d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use indexes of when crossover is 1 to change cam_view to 0 for three seconds after crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f6cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2. VideoCapture(\"Batman Left.mp4\")\n",
    "vlength = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "alength=len(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df113f99",
   "metadata": {},
   "source": [
    "## Create intervals of data in tuple form. \n",
    "## Audio Tuples represent the start and end frame of when mic is dominant. Camera 0 is default cam in case of uncertainty, which is center cam in this scenario.\n",
    "## Video Tuples represent the start and end frame of which mic to use. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf64797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_getintervals(series,desiredvalue):\n",
    "    #make sure series is the df['column']\n",
    "    t=series.index[series==desiredvalue].to_series()\n",
    "    interval_list=t.groupby(t.diff().ne(1).cumsum()).agg(['first','last']).apply(tuple,1).tolist()\n",
    "    \n",
    "    return interval_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb2df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lists of tuples for each camera based on the audio\n",
    "\n",
    "list_of_idxmax_mic_data=[]\n",
    "for i in range(len(AUDIO_VIDEO_TUPLE_LIST)+1):\n",
    "    tuple_list=dataframe_getintervals(data_df['idxmax'],i)\n",
    "    list_of_idxmax_mic_data.append(tuple_list)\n",
    "\n",
    "    \n",
    "##create lists of tuples for each Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c166200e",
   "metadata": {},
   "source": [
    "# Variables and their definitions\n",
    "\n",
    "```py \n",
    "list_of_idxmax_mic_data  \n",
    "```\n",
    "- List of lists of tuples defining the (starting frame, ending frame)\n",
    "- Position on the list describes which audio file is used, where 0 is unsure\n",
    "- IE: list_of_idxmax_mic_data[1] is the (starting frame, ending frame) of Audio file 1\n",
    "\n",
    "\n",
    "\n",
    "```py \n",
    "VIDEO_FILEPATH_LIST  \n",
    "```\n",
    "- List of video filepaths. \n",
    "- We will use the list indexes to reference audio video pairs in the next variable\n",
    "\n",
    "```py \n",
    "AUDIO_VIDEO_TUPLE_LIST \n",
    "```\n",
    "- A Tuple of (Audio Filepath, VIDEO_FILEPATH_LIST index of associated audio)\n",
    "- use this to connect a audio to video track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55566332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skeletal outline of otio\n",
    "\n",
    "\n",
    "# build the structure\n",
    "tl = otio.schema.Timeline(name=\"Example timeline\")\n",
    "\n",
    "# add track for each video file and each audio file\n",
    "#for each file add a track\n",
    "\n",
    "#create lists for each track to reference back to later\n",
    "#vtr is video track, etc.\n",
    "vtr_list=[]\n",
    "atr_list=[]\n",
    "\n",
    "\n",
    "#add a audio AND video track for each video track\n",
    "    #default cam first because it is lowest priority\n",
    "vtr_default = otio.schema.Track(name=\"Default_camera\", kind=\"Video\")\n",
    "tl.tracks.append(vtr_default)\n",
    "\n",
    "for i in AUDIO_VIDEO_TUPLE_LIST:\n",
    "    atr = otio.schema.Track(name=i[0], kind=\"Audio\")\n",
    "    tl.tracks.append(atr)\n",
    "    atr_list.append(atr)\n",
    "    \n",
    "    #video\n",
    "    vtr = otio.schema.Track(name=i[0]+\"_video\", kind=\"Video\")\n",
    "    tl.tracks.append(vtr)\n",
    "    vtr_list.append(vtr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f0ef5",
   "metadata": {},
   "source": [
    "        v_clip_available_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(0, vrate),\n",
    "                duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "\n",
    "### Available range returns the specified TimeRange available via the Clip’s media_reference. This should tell you how long that movie is and what timecode it starts at. For example: “wedding.mov” starts at timecode 01:00:00:00 and is 30 minutes long.\n",
    "        vclip_ref = otio.schema.ExternalReference(target_url=vfname,\n",
    "            available_range=vclip_timerange)\n",
    "        \n",
    "        \n",
    "        vcl = otio.schema.Clip(\n",
    "                    name=\"vClip{}\".format(i2 + 1),\n",
    "                    media_reference=vclip_ref,\n",
    "\n",
    "###  The Source range  of a Clip will trim the Clip to only that range of media.\n",
    "                    # available_range_from_list is the \n",
    "                    source_range=otio.opentime.TimeRange(\n",
    "                        start_time=otio.opentime.RationalTime(\n",
    "                            vclip_timerange.start_time.value,\n",
    "                            vclip_timerange.start_time.rate\n",
    "                        ),\n",
    "                        duration=otio.opentime.RationalTime(\n",
    "                            vclip_timerange.duration.value,\n",
    "                            vclip_timerange.duration.rate\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        vtrack.append(vcl)\n",
    "        \n",
    "        \n",
    "        vstartingframe=0\n",
    "        astartingframe=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29006bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "otio.schema.Track(name='Scott Audio Extracted.wav_video', children=[], source_range=None, metadata={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtr_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c171267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vrate=24\n",
    "arate=500\n",
    "arate_actual=24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ec573",
   "metadata": {},
   "source": [
    "# Two different loops, One for Video, another for audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1e12861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        #print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            v_clip_starttime=tuples[0]/arate*vrate\n",
    "            v_clip_duration=tuples[1]/arate*vrate-v_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            v_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, vrate),\n",
    "            duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "            \n",
    "            vref = otio.schema.ExternalReference(target_url=vfname,\n",
    "            available_range=v_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            v_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_clip_starttime, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_clip_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            v_gap_start_time=0\n",
    "            v_gap_duration=v_clip_starttime-vprevious_end_timecode\n",
    "            \n",
    "            v_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_gap_start_time, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_gap_duration, vrate))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            vgap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.start_time.value,\n",
    "                        v_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.duration.value,\n",
    "                        v_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            vtrack.append(vgap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            vcl = otio.schema.Clip(\n",
    "                        name=\"vClip{}\".format(i2 + 1),\n",
    "                        media_reference=vref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.start_time.value,\n",
    "                                v_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.duration.value,\n",
    "                                v_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            vtrack.append(vcl)\n",
    "\n",
    "            vprevious_end_timecode=tuples[1]/arate*vrate\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c89026bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Osi Audio Extracted.wav', 1) Batman Right.mp4\n",
      "('Scott Audio Extracted.wav', 1) Batman Right.mp4\n",
      "('Chukwu Audio Extracted.wav', 2) Batman Left.mp4\n",
      "('Crystal Audio Extracted.wav', 2) Batman Left.mp4\n"
     ]
    }
   ],
   "source": [
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            a_clip_starttime=tuples[0]/arate*arate_actual\n",
    "            a_clip_duration=tuples[1]/arate*arate_actual-a_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            a_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, arate_actual),\n",
    "            duration=otio.opentime.RationalTime(alength*arate_actual, arate_actual))\n",
    "            \n",
    "            aref = otio.schema.ExternalReference(target_url=afname,\n",
    "            available_range=a_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            a_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_clip_starttime, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_clip_duration, arate_actual))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            a_gap_start_time=0\n",
    "            a_gap_duration=a_clip_starttime-aprevious_end_timecode\n",
    "            \n",
    "            a_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(a_gap_start_time, arate_actual),\n",
    "                duration=otio.opentime.RationalTime(a_gap_duration, arate_actual))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            agap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.start_time.value,\n",
    "                        a_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        a_gap_timerange.duration.value,\n",
    "                        a_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            atrack.append(agap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            acl = otio.schema.Clip(\n",
    "                        name=\"aClip{}\".format(i2 + 1),\n",
    "                        media_reference=aref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.start_time.value,\n",
    "                                a_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                a_clip_source_range.duration.value,\n",
    "                                a_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            atrack.append(acl)\n",
    "\n",
    "            aprevious_end_timecode=tuples[1]/arate*arate_actual\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42f30bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'videoaudio_beta1.xml'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otio.adapters.write_to_file(tl, 'videoaudio_beta1.otio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06242bb9",
   "metadata": {},
   "source": [
    "# List of starting time of being the dominant speaker and the duration\n",
    "```py\n",
    "('Data/Audio/Osi Audio Extracted.wav', 1)\n",
    "('Data/Audio/Osi Audio Extracted.wav', 1) Batman Right.mp4\n",
    "5.0 5.814\n",
    "52.256 68.582\n",
    "150.312 24.148\n",
    "330.572 33.254\n",
    "495.476 11.958\n",
    "508.292 4.256\n",
    "631.932 2.57\n",
    "672.094 16.796\n",
    "716.55 6.716\n",
    "739.93 8.774\n",
    "753.63 6.882\n",
    "781.768 4.996\n",
    "848.5 2.53\n",
    "855.804 14.33\n",
    "915.096 95.554\n",
    "1054.966 18.062\n",
    "1131.93 3.532\n",
    "1250.422 1.634\n",
    "1265.846 8.658\n",
    "1278.098 19.812\n",
    "('Data/Audio/Scott Audio Extracted.wav', 1) Batman Right.mp4\n",
    "29.878 13.236\n",
    "44.242 5.452\n",
    "120.84 29.47\n",
    "253.812 2.886\n",
    "507.436 0.854\n",
    "538.042 2.076\n",
    "618.74 4.106\n",
    "634.504 6.394\n",
    "688.892 16.592\n",
    "711.148 5.4\n",
    "723.268 2.732\n",
    "748.706 4.922\n",
    "895.318 16.53\n",
    "1010.652 9.78\n",
    "1025.558 12.08\n",
    "1215.542 34.878\n",
    "1258.498 7.346\n",
    "1297.912 1.248\n",
    "('Data/Audio/Chukwu Audio Extracted.wav', 2) Batman Left.mp4\n",
    "10.816 12.376\n",
    "43.116 1.124\n",
    "49.696 2.558\n",
    "247.8 6.01\n",
    "256.7 26.724\n",
    "287.506 6.202\n",
    "370.096 45.72\n",
    "453.658 4.122\n",
    "512.55 25.49\n",
    "540.12 41.926\n",
    "589.822 19.068\n",
    "629.012 2.918\n",
    "706.598 4.548\n",
    "726.002 6.506\n",
    "760.514 13.74\n",
    "778.346 3.42\n",
    "786.766 27.816\n",
    "1020.924 4.632\n",
    "1073.03 34.318\n",
    "1185.776 15.498\n",
    "1208.034 7.506\n",
    "1299.354 3.456\n",
    "('Data/Audio/Crystal Audio Extracted.wav', 2) Batman Left.mp4\n",
    "23.194 6.682\n",
    "174.462 73.336\n",
    "283.426 4.078\n",
    "293.71 36.86\n",
    "363.828 6.266\n",
    "415.818 37.838\n",
    "457.782 37.692\n",
    "582.048 7.772\n",
    "608.892 9.846\n",
    "622.848 6.162\n",
    "640.9 31.192\n",
    "705.486 1.11\n",
    "732.51 7.418\n",
    "774.256 4.088\n",
    "814.584 33.914\n",
    "851.032 4.77\n",
    "870.136 25.18\n",
    "911.85 3.244\n",
    "1020.434 0.488\n",
    "1037.64 17.324\n",
    "1107.35 24.578\n",
    "1135.464 50.31\n",
    "1201.276 6.756\n",
    "1252.058 6.438\n",
    "1274.506 3.59\n",
    "1299.162 0.19\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc08d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2. VideoCapture(\"Batman Left.mp4\")\n",
    "vlength = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "alength=len(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aed1c",
   "metadata": {},
   "source": [
    "# The clip adding via tuple looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18b362ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Data/Audio/Osi Audio Extracted.wav', 1) Batman Right.mp4\n",
      "('Data/Audio/Scott Audio Extracted.wav', 1) Batman Right.mp4\n",
      "('Data/Audio/Chukwu Audio Extracted.wav', 2) Batman Left.mp4\n",
      "('Data/Audio/Crystal Audio Extracted.wav', 2) Batman Left.mp4\n"
     ]
    }
   ],
   "source": [
    "# i is to keep track which audio file we are currently on\n",
    "i=-1\n",
    "\n",
    "# i2 is to keep track of how many clips there are\n",
    "i2=0\n",
    "\n",
    "for lists_of_tuples in list_of_idxmax_mic_data:\n",
    "    #connect the list of tuples to the audio file\n",
    "    #ignore 0 for now. We will come back to this later, i will still be -1 but we will add a default clip instead\n",
    "    \n",
    "    if i==-1:\n",
    "    #add the entire default cam clip in the lowest priority\n",
    "        #vclip\n",
    "        #aclip\n",
    "        pass\n",
    "    \n",
    "    else: \n",
    "        print(AUDIO_VIDEO_TUPLE_LIST[i],VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]])\n",
    "    \n",
    "        # Connect the audio and video tracks \n",
    "        atrack=atr_list[i]\n",
    "        afname=AUDIO_VIDEO_TUPLE_LIST[i][0]\n",
    "        \n",
    "        # AUDIO_VIDEO_TUPLE_LIST[i][1] references the VIDEO_FILEPATH_LIST to determine which video file to use\n",
    "        vtrack=vtr_list[i]\n",
    "        vfname=VIDEO_FILEPATH_LIST[AUDIO_VIDEO_TUPLE_LIST[i][1]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #will remember the previous end of clip's timecode\n",
    "        #will reset to 0 when a video-audio track pair is done\n",
    "        vprevious_end_timecode=0\n",
    "        aprevious_end_timecode=0\n",
    "        \n",
    "    #=========================================================================\n",
    "           \n",
    "        for tuples in lists_of_tuples:\n",
    "            \n",
    "        #=====================================================\n",
    "          #adding variables for time and duration calculation\n",
    "            #Video clips \n",
    "            v_clip_starttime=tuples[0]/arate*vrate\n",
    "            v_clip_duration=tuples[1]/arate*vrate-v_clip_starttime\n",
    "\n",
    "            \n",
    "        #Specifying the start time and end time of the video file where clips come from\n",
    "            v_clip_available_range=otio.opentime.TimeRange(\n",
    "            start_time=otio.opentime.RationalTime(0, vrate),\n",
    "            duration=otio.opentime.RationalTime(vlength, vrate))\n",
    "            \n",
    "            vref = otio.schema.ExternalReference(target_url=vfname,\n",
    "            available_range=v_clip_available_range)\n",
    "            \n",
    "            \n",
    "        #specifying where the start timecode and end timecode of the clip is\n",
    "            v_clip_source_range=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_clip_starttime, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_clip_duration, vrate))\n",
    "\n",
    "\n",
    "\n",
    "        #Video Gaps\n",
    "            #the gap length is equal to (timecode of next clip time - timecode end of previous clip)\n",
    "            v_gap_start_time=0\n",
    "            v_gap_duration=v_clip_starttime-vprevious_end_timecode\n",
    "            \n",
    "            v_gap_timerange=otio.opentime.TimeRange(\n",
    "                start_time=otio.opentime.RationalTime(v_gap_start_time, vrate),\n",
    "                duration=otio.opentime.RationalTime(v_gap_duration, vrate))\n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "         #=====================================================   \n",
    "            # adding gaps before adding clips\n",
    "            #convert the tuple ranges from audio rate to video rate\n",
    "                #audio rate=500\n",
    "                #video rate=24\n",
    "\n",
    "\n",
    "\n",
    "            # create gap settings\n",
    "            vgap = otio.schema.Gap(\n",
    "                name=\"vGap{}\".format(i2 + 1),\n",
    "\n",
    "                # available_range_from_list is the \n",
    "                source_range=otio.opentime.TimeRange(\n",
    "                    start_time=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.start_time.value,\n",
    "                        v_gap_timerange.start_time.rate\n",
    "                    ),\n",
    "                    duration=otio.opentime.RationalTime(\n",
    "                        v_gap_timerange.duration.value,\n",
    "                        v_gap_timerange.duration.rate\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # put the clip into the track\n",
    "            vtrack.append(vgap)\n",
    "\n",
    "\n",
    "\n",
    "        #=======================================================\n",
    "        # adding Video clips \n",
    "        #convert the tuple ranges from audio rate to video rate\n",
    "        #audio rate=500\n",
    "\n",
    "                        #add clip to track                \n",
    "\n",
    "            vcl = otio.schema.Clip(\n",
    "                        name=\"vClip{}\".format(i2 + 1),\n",
    "                        media_reference=vref,\n",
    "\n",
    "                        # available_range_from_list is the \n",
    "                        source_range=otio.opentime.TimeRange(\n",
    "                            start_time=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.start_time.value,\n",
    "                                v_clip_source_range.start_time.rate\n",
    "                            ),\n",
    "                            duration=otio.opentime.RationalTime(\n",
    "                                v_clip_source_range.duration.value,\n",
    "                                v_clip_source_range.duration.rate\n",
    "                            ),\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            vtrack.append(vcl)\n",
    "\n",
    "            vprevious_end_timecode=tuples[1]/arate*vrate\n",
    "            #apreviousduration=\n",
    "        \n",
    "\n",
    "\n",
    "            i2=i2+1\n",
    "\n",
    "            \n",
    "    i=i+1\n",
    "    #if i == 2:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91c1fff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505.5839999999989"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_gap_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7786363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otio.adapters.write_to_file(tl, 'videoclipsonly.otio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment analysis Duration is NOT DURATION. it is the end time!\n",
    "# start time 2400 is a hundered seconds in\n",
    "# duration 4800 is that the clip goes for 2400 until it reaches 4800 at the end time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "otio.schema.Clip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b3c6dfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "otio.schema.Track(name='Data/Audio/Osi Audio Extracted.wav_video', children=[otio.schema.Gap(name='vGap1', source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=0, rate=24), duration=otio.opentime.RationalTime(value=120, rate=24)), effects=[], markers=[], metadata={}), otio.schema.Clip(name='vClip1', media_reference=otio.schema.ExternalReference(target_url='Batman Right.mp4'), source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=120, rate=24), duration=otio.opentime.RationalTime(value=259.536, rate=24)), metadata={}), otio.schema.Gap(name='vGap2', source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=0, rate=24), duration=otio.opentime.RationalTime(value=994.608, rate=24)), effects=[], markers=[], metadata={}), otio.schema.Clip(name='vClip2', media_reference=otio.schema.ExternalReference(target_url='Batman Right.mp4'), source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=1254.14, rate=24), duration=otio.opentime.RationalTime(value=2900.11, rate=24)), metadata={}), otio.schema.Gap(name='vGap3', source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=0, rate=24), duration=otio.opentime.RationalTime(value=707.376, rate=24)), effects=[], markers=[], metadata={}), otio.schema.Clip(name='vClip3', media_reference=otio.schema.ExternalReference(target_url='Batman Right.mp4'), source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=3607.49, rate=24), duration=otio.opentime.RationalTime(value=4187.04, rate=24)), metadata={}), otio.schema.Gap(name='vGap4', source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=0, rate=24), duration=otio.opentime.RationalTime(value=3746.69, rate=24)), effects=[], markers=[], metadata={}), otio.schema.Clip(name='vClip4', media_reference=otio.schema.ExternalReference(target_url='Batman Right.mp4'), source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=7933.73, rate=24), duration=otio.opentime.RationalTime(value=8731.82, rate=24)), metadata={}), otio.schema.Gap(name='vGap5', source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=0, rate=24), duration=otio.opentime.RationalTime(value=3159.6, rate=24)), effects=[], markers=[], metadata={}), otio.schema.Clip(name='vClip5', media_reference=otio.schema.ExternalReference(target_url='Batman Right.mp4'), source_range=otio.opentime.TimeRange(start_time=otio.opentime.RationalTime(value=11891.4, rate=24), duration=otio.opentime.RationalTime(value=12178.4, rate=24)), metadata={})], source_range=None, metadata={})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtr_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_to_otio_test=otio.adapters.read_from_file('sc')\n",
    "otio.adapters.write_to_file(xml_to_otio_test, \"tests.otio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ccc16e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "otio.schema.Timeline(name='', tracks=otio.schema.Stack(name='tracks', children=[], source_range=None, metadata={}))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otio.schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b599c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
